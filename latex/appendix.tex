\appendix
\section*{\begin{center}{\Huge Appendix}\end{center}}
\addcontentsline{toc}{chapter}{Appendix}
% $\\[0.5cm]$


\chapter{Implementation Details} % (fold)
\label{cha:implementation_details}

\section{All Pairs Shortest Path} % (fold)
\label{sec:all_pairs_shortest_path}

When we a route parts of our fitness evaluation rely on the distance between elements in the graph. To make the process of aquiring the distances fast and legible in the code we chose to use an all pairs shortes path matrix (SOURCE), and to construct it we relied on the Floyd-Warshall algorithm (SOURCE). In a lot of the literature Dijkstras algorithm (SOURCE) is used iteratively for this purpose (SOURCES). However, because it has the same asympthotical running time (SOURCE) and it has a much more compact syntax, we chose to work with the Floyd-Warshall algorithm.
\\\\
Due to that our graph represents a NEARP, and we therefore wanted the all pairs shortest path matrix to hold the shortest path betwee all the elements in the graph (not just nodes, but nodes, arcs, and edges), we ran into some challenges. Usually one would look at the distance between nodes, and the way Floyd-Warshall constructs the matrix, nodes with no distance are effectively treated as the same node. When we interpret going onto an arc as having no cost, and going of an arc to the node it is connected to as not having any cost, the algorithm interprets going from the first to the second node as having no cost, and them effectively being the same node for calculating further costs/distances.
\\\\
Essentially we ended up in a situation where there would be no cost going to a neighbor, but passing through it to the next neighbor would have a cost.



\begin{algorithm}
\caption{Floyd-Warshall}\label{floyd-warshall-pseudocode}
\begin{algorithmic}[1]

\Procedure{Floyd-Warshall}{Graph}
	\State \textbf{let} $numberOfElements \leftarrow \sum (|N|+|E|+|A|) \in Graph$
	\State \textbf{let} $distances$ be a $numberOfElements \times numberOfElements$ array
	\State \textbf{let} $successors$ be a $numberOfElements \times numberOfElements$ array
	\State \textbf{set} all entries in $distances$ to $\infty$
	\State \textbf{set} all entries in $successors$ to $-1$
	\For{\textbf{each} element $e \in N \cup E \cup A \in Graph$}
		\State $distances[e][e] \leftarrow 0$
		\State $successors[e][e] \leftarrow e$
	\EndFor
	\For{\textbf{each} element $e \in N \cup E \cup A \in Graph$}
		\State \textbf{let} $adjacent \leftarrow $ elements adjacent to $e$ in $Graph$
		\For{\textbf{each} element $e_a \in adjacent$}
			\State $distances[e][e_a] \leftarrow e_a.passThroughCost$
			\State $successors[e][e_a] \leftarrow e_a$
			\State $successors[e_a][e] \leftarrow e$
		\EndFor
	\EndFor
	\For{$k \leftarrow 0$ \textbf{to} $numberOfElements$}
		\For{$i \leftarrow 0$ \textbf{to} $numberOfElements$}
			\For{$j \leftarrow 0$ \textbf{to} $numberOfElements$}
				\If{$distances[i][j] > distances[i][k] + distances[k][j]$}
					\State $distances[i][j] = distances[i][k] + distances[k][j]$
					\State $successors[i][j] = successors[i][k]$
				\EndIf
			\EndFor
		\EndFor
	\EndFor
	\For{\textbf{each} element $(e_i,e_j) \in N \cup E \cup A \in Graph$}
		\If{$e_i \neq e_j$}
			\State $distances[e_j][e_i] \leftarrow distances[e_j][e_i] - e_i.passThroughCost$
		\EndIf
	\EndFor
\EndProcedure

\end{algorithmic}
\end{algorithm}

% section all_pairs_shortest_path (end)

\section{Split Heuristic} % (fold)
\label{sec:split_heuristic}

The psudocod for the split algorithm:

\begin{algorithm}
\caption{Split}\label{split-pseudocode}
\begin{algorithmic}[1]

\Procedure{Split}{Graph,Distances}
	\State \textbf{let} $numberOfElements \leftarrow \sum (|N|+|E|+|A|) \in Graph$
	\State \textbf{let} $costs$ be an array of length $numberOfElements + 1$
	\State \textbf{let} $predecessors$ be an array of length $numberOfElements + 1$
	\State \textbf{set} all entries in $predecessors$ to $\infty$
	\State $costs[0] \leftarrow 0$
	\State $predecessors[0] \leftarrow 0$
	\For{$i \leftarrow 1$ \textbf{to} $numberOfElements + 1$}
		\State $j \leftarrow i$
		\State $load \leftarrow 0$
		\State $cost \leftarrow 0$
	\EndFor
\EndProcedure

\end{algorithmic}
\end{algorithm}

% section split_heuristic (end)

\section{Evolutionary Algorithm} % (fold)
\label{sec:evolutionary_algorithm}

\subsection{Genome} % (fold)
\label{sub:genome}
% subsection genome (end)

% section evolutionary_algorithm (end)

% chapter implementation_details (end)

\chapter{Evolutionary Algorithm Configuration} % (fold)
\label{cha:evolutionary_algorithm_configuration}

\section{Background and Motivation} % (fold)
\label{sec:background_and_motivation}
Here we outline how we determined what parameters to use when running the EA. There were several features that could be tweaked or enabled and disabeled when we made the EA. For an instance the population size and number of parents that get get to reproduce each generation are values that can be adjusted, while wheter to use random mutation or memetic optimization is a choice of whether to use one of two implementation.
\\\\
Some combinations of the parametes yield higher quality results faster (both in terms of actual time spent and number of generations passed before the output stabilizes, ie. the program reaches a local optimumum). Therefore we were interested in determining the best combination of parameters.
\\\\
Initially these were the parameters for EA that the user could set.
\begin{itemize}
	\item How the genomes that would get to produce children were selected.
	\item How the nex generation would be produced from the current set of adults and children.
	\item Whether the fitness should evaluate one grand tour for one wehcile or consider a case where the given area should be divided among a set of vehicles.
	\item The maximal number of generations the algorithm should run for before terminating.
	\item If the algorithm gets stuck in a local optimum, for how many generations should it continue trying to get out of there before acknowledging that it is stuck and just returning the best answer it has.
	\item The number of individuals to have in the population at the beginning of a generation.
	\item How many individuals to select from the population that gets to mate each generation.
	\item How many pairs to make from the selected parents.
	\item If parents are selected tournament-style, what size (in terms of number of individuals) should each tournament group be.
	\item If parents are selected tournament-style, what should be the probability of selecting the best individual from each tournament group each iteration of the tournament.

\end{itemize}
% section background_and_motivation (end)

\section{Experimental Plan} % (fold)
\label{sec:experimental_plan}
% This should be the section about what we want to do, and why we want to do it
To keep the results as relevant as possible for the final use case we found that running the tests on actual data from NVDB would be prudent. Vill en sone være represenattiv for alle soner? Bruke det til å agumentere for at vi like gjerne kan bruke et annet datasett så lenge inputformatet er ish det samme.

Experiments:
For each parameter, we wanted to do 10 runs to determine average values for each configuration with several random seeds. 

Vary number of individuals: start with a low, medium, and high number of individuals in terms of the genome size (eg. populations the size of 50\%, 100\%, and 200\% of the genome length). Based on the initial observations try inter- or extrapolating untill results of a good enough fitness are reached fast enough.

Max generations: so long that you get stuck before you reach it, but don't have to wait forever for it to terminate. For testing purposes: run it for indefinitely a couple of times, and see how long it takes before it has been stuck for a booringly long time. Take a number of generations that is higher than the time it spends stuck in local optima up to that point, and use that.
Keep in mind that this will vary with input size, so it really has to be manually tuned for each input. Is more for the sake of the developer/tweaker.

Generational replacement: After having found a population size, run each way of doing it for the same number of times as when finding number of individuals. Treat combinations of overproduction and number of children as separate configurations in these tests.

Parent selection: Same as generational replacement. Treat combinations of tutnament selection, size, and probability as separate entries here.

At this point test random mutation vs memetic improvement?
% section experimental_plan (end)

\section{Experimental Setup} % (fold)
\label{sec:experimental_setup}
% This section should be about how we did the experiments, ie. what parameters we used and so forth
The areas we chose for collecting the data was **TODO**. For verification we used the area **TODO**.

For the tuning, we chose to use the BHW1 data set. The main reason for this is that its size is rather small, so it was feasible to many iterations on it. Furthermore, since we assume the parameters to have a similar comparative performance relative to eachother, there is no reason to run it on one of our final data sets other than to get an indication of the performance versus time. Because this experiment is about finding what parameters work best, and we can test how fast the EA performs separately, this seems like a fair approach.

To make the results easier to compare, we ran the system for X generations each time, but without stopping when the algorithm seemed stuck in a local optimum. This has the advantage of giving us the same scale on all the resulting graphs.

All the genotypes get initialized randomly.

Will be plotting number of generations vs fitness. Averages of the best of the runs, and averages of averages. 
% section experimental_setup (end)

\section{Results} % (fold)
\label{sec:results}

% section results (end)

\section{Evaluation and Conclusion} % (fold)
\label{sec:evaluation_and_conclusion}

% section evaluation_and_conclusion (end)

% chapter evolutionary_algorithm_configuration (end)
